#Choose a subset of S: A_t, which has k elements
kRandomIndicies = sample(nrow(X), k, replace = FALSE)
A_t = S[kRandomIndicies,]
#Set A_tPlus to be the elements of A_t that have y<w_t,x> < 1
yinA_t = A_t[,ncol(X) + 1]
XinA_t = A_t[,1:ncol(X)]
A_tPlus = A_t
#A_tPlus = subset(A_t, yinA_t * (XinA_t %*% w_t) < 1)
for(i in 1:nrow(A_t)) {
if (yinA_t[i] * (XinA_t[i,] %*% w_t) >= 1){
A_tPlus[i,] = 0
print("POOOOOOOOOOP")
}
}
# Set eta
eta_t = 1/ (lam * t)
# Set w_tPlusHalf
x_tPlus = A_tPlus[,1:ncol(X)]
y_tPlus = A_tPlus[,ncol(X) + 1]
print(dim(y_tPlus * x_tPlus))
print(t)
w_tPlusHalf = (1 - eta_t * lam) * w_t + (eta_t / k) * colSums(y_tPlus * x_tPlus)
# Set w_t+1
candidate = (1/sqrt(lam)) / (sqrt(sum(w_tPlusHalf^2)))
w_t = min(1, candidate) * w_tPlusHalf
}
return(w_t)
#rep(0,ncol(X)) # this is the right dimension for the output
}
my_primal_svm(X1, y1)
source("http://www.bioconductor.org/getBioC.R")
source("https://bioconductor.org/biocLite.R")
biocLite("affy")
biocLite()
source("https://bioconductor.org/biocLite.R")
biocLite("affy")
biocLite("oligo")
biocLite("limma")
library(affy)
data = ReadAffy()
source("https://bioconductor.org/biocLite.R")
biocLite()
biocLite("BiocStyle")
biocLite("ALL")
biocLite
biocLITE("airway")
biocLite("airway")
biocLite("microbenchmark")
biocLite("affy")
source("https://bioconductor.org/biocLite.R")
biocLite("limma")
biocLite()
library(affy)
biocLite("affy")
??TxDb.Hsapiens.UCSC.hg19.knownGene
install.packages("txdb.hsapiens.ucsc.hg19.knowngene")
source("https://bioconductor.org/biocLite.R")
biocLite("TxDb.Hsapiens.UCSC.hg19.knownGene")
source("https://bioconductor.org/biocLite.R")
source("https://bioconductor.org/biocLite.R")
biocLite("BSgenome.Hsapiens.UCSC.hg19")
?aggregate
library("airway")
install.packages("rJava")
?rjava
biocLite()
source("https://bioconductor.org/biocLite.R")
biocLite("survival")
setwd("C:/Users/Justin/Desktop/TextData")
source("https://bioconductor.org/biocLite.R")
readtext = function(filename){
textFileString = readChar(paste(filename, ".txt", sep = "")
, file.info(paste(filename, ".txt", sep = ""))$size)
textFileString = gsub("\r?\n|\r", " ", textFileString)
textFileString = gsub("<.*?>", " ", textFileString)
wordFrequenciesTable = table(unlist(strsplit(tolower(textFileString), "\\W")))
wordFrequenciesTable.df = as.data.frame(wordFrequenciesTable)
colnames(wordFrequenciesTable.df) = c('word', 'freq')
return(as.data.frame(wordFrequenciesTable.df))
}
#Fitzgerald Stuff
setwd("C:/Users/Justin/Desktop/TextData/Fitzgerald")
f1 = readtext("winterdreams")
f2 = readtext("bernicebobsherhair")
f3 = readtext("headandshoulders")
f4 = readtext("theicepalace")
f5 = readtext("theoffshorepirate")
f6 = readtext("thecuriouscaseofbenjaminbutton")
f7 = readtext("thebabyparty")
f8 = readtext("thefreshestboy")
f9 = readtext("thebridalparty")
f10 = readtext("anewleaf")
f11 = readtext("babylonrevisited")
f12 = readtext("crazysunday")
f13 = readtext("MayDay")
f14 = readtext("TheJellyBean")
f15 = readtext("TheCamelsBack")
f16 = readtext("PorcelainAndPink")
f17 = readtext("TheLeesOfHappiness")
f18 = readtext("MrIcky")
f19 = readtext("JeminaTheMountainGirl")
f20 = readtext("TheCutGlassBowl")
setwd("C:/Users/Justin/Desktop/TextData")
#Chekhov Stuff
setwd("C:/Users/Justin/Desktop/TextData/Chekhov")
c1 = readtext("adoctorsvisit")
c2 = readtext("theladywiththedog")
c3 = readtext("alivingchattel")
c4 = readtext("aboutlove")
c5 = readtext("thegrasshopper")
c6 = readtext("whowastoblame")
c7 = readtext("ananonymousstory")
c8 = readtext("volodya")
c9 = readtext("theprincess")
c10 = readtext("thedeathofagovernmentclerk")
c11 = readtext("theninny")
c12 = readtext("thebetrothed")
c13 = readtext("AStoryWithoutATitle")
c14 = readtext("Peasants")
c15 = readtext("AnArtistsStory")
c16 = readtext("AtHome")
c17 = readtext("AtChristmasTime")
c18 = readtext("TheDarling")
c19 = readtext("ANervousBreakdown")
c20 = readtext("Sleepy")
c21 = readtext("Boys")
c22 = readtext("Uprooted")
c23 = readtext("Happiness")
c24 = readtext("BadWeather")
c25 = readtext("Darkness")
c26 = readtext("TheLotteryTicket")
c27 = readtext("AMystery")
c28 = readtext("Frost")
c29 = readtext("Champagne")
c30 = readtext("Drunk")
c31 = readtext("Enemies")
setwd("C:/Users/Justin/Desktop/TextData")
#Pop Music
setwd("C:/Users/Justin/Desktop/TextData/PopMusic")
p1 = readtext("work")
p2 = readtext("7years")
p3 = readtext("whereisthelove")
p4 = readtext("OneDance")
p5 = readtext("Californication")
p6 = readtext("StairwaytoHeaven")
p7 = readtext("BohemianRhapsody")
p8 = readtext("HotelCalifornia")
p9 = readtext("Chandelier")
p10 = readtext("Heroes")
p11 = readtext("ManInTheMirror")
p12 = readtext("MyHeartWillGoOn")
p13 = readtext("CircleOfLife")
p14 = readtext("AWholeNewWorld")
p15 = readtext("BeautyAndTheBeast")
p16 = readtext("OneDayMore")
p17 = readtext("Memory")
p18 = readtext("MoMoneyMoProblems")
p19 = readtext("IDreamedADream")
p20 = readtext("Changes")
p21 = readtext("DearMama")
p22 = readtext("KeepYaHeadUp")
p23 = readtext("HeyJude")
p24 = readtext("WithOrWithoutYou")
p25 = readtext("BeautifulDay")
p26 = readtext("PaintItBlack")
p27 = readtext("Desperado")
p28 = readtext("EyeOfTheTiger")
p29 = readtext("NovemberRain")
p30 = readtext("IWillAlwaysLoveYou")
p31 = readtext("Human")
p32 = readtext("21Guns")
setwd("C:/Users/Justin/Desktop/TextData")
#Seminal Papers
setwd("C:/Users/Justin/Desktop/TextData/SeminalPapers")
sp1 = readtext("ridgeregression")
sp2 = readtext("rulefit")
sp3 = readtext("iPSC")
sp4 = readtext("proteinmeasurement")
sp5 = readtext("TheProblemOfSocialCost")
sp6 = readtext("InactivationEColi")
sp7 = readtext("GenomeCluster")
sp8 = readtext("MicroarraysIonization")
sp9 = readtext("ProteinDyeLabeling")
sp10 = readtext("DNASequencing")
sp11 = readtext("RNAIsolation")
sp12 = readtext("WesternBlot")
sp13 = readtext("ElectronDensity")
sp14 = readtext("ThermoChemistry")
sp15 = readtext("BasicLocalAlignment")
sp16 = readtext("SHELX")
sp17 = readtext("BLAST")
sp18 = readtext("SocialMedia")
sp19 = readtext("CRISPR")
sp20 = readtext("GeneticAlgorithms")
setwd("C:/Users/Justin/Desktop/TextData")
#Hemingways
setwd("C:/Users/Justin/Desktop/TextData/Hemingway")
h1 = readtext("TheShortHappyLifeofFrancisMacomber")
h2 = readtext("TheCapitaloftheWorld")
h3 = readtext("TheSnowsofKilimanjaro")
h4 = readtext("OldManattheBridge")
h5 = readtext("UpinMichigan")
h6 = readtext("OntheQuaiatSmyrna")
h7 = readtext("IndianCamp")
h8 = readtext("TheDoctorandtheDoctorsWife")
h9 = readtext("TheEndofSomething")
h10 = readtext("The Three-Day Blow")
h11 = readtext("TheBattler")
h12 = readtext("AVeryShortStory")
h13 = readtext("SoldiersHome")
h14 = readtext("TheRevolutionist")
h15 = readtext("MrandMrsElliot")
h16 = readtext("CatintheRain")
h17 = readtext("OutofSeason")
h18 = readtext("CrossCountrySnow")
h19 = readtext("MyOldMan")
h20 = readtext("BigTwoHeartedRiverPart1")
h21 = readtext("BigTwoHeartedRiverPart2")
h22 = readtext("TheUndefeated")
h23 = readtext("InAnotherCountry")
h24 = readtext("HillsLikeWhiteElephants")
h25 = readtext("TheKillers")
h26 = readtext("CheTiDiceLaPatria")
h27 = readtext("FiftyGrand")
h28 = readtext("ASimpleEnquiry")
h29 = readtext("TenIndians")
h30 = readtext("ACanaryforOne")
h31 = readtext("AnAlpineIdyll")
h32 = readtext("APursuitRace")
h33 = readtext("BanalStory")
h34 = readtext("NowILayMe")
h35 = readtext("acleanwelllightedplace")
setwd("C:/Users/Justin/Desktop/TextData")
#O'Connor
setwd("C:/Users/Justin/Desktop/TextData/OConnor")
oc1 = readtext("TheGeranium")
oc2 = readtext("TheBarber")
oc3 = readtext("Wildcat")
oc4 = readtext("TheCrop")
oc5 = readtext("TheTurkey")
oc6 = readtext("TheTrain")
oc7 = readtext("ThePeeler")
oc8 = readtext("TheHeartOfThePark")
oc9 = readtext("AStrokeOfGoodFortune")
oc10 = readtext("EnochAndTheGorilla")
oc11 = readtext("AGoodManIsHardToFind")
oc12 = readtext("ALateEncounterWithTheEnemy")
oc13 = readtext("TheLifeYouSaveMayBeYourOwn")
oc14 = readtext("TheRiver")
oc15 = readtext("ACircleInTheFire")
oc16 = readtext("TheDisplacedPerson")
oc17 = readtext("ATempleOfTheHolyGhost")
oc18 = readtext("TheArtificialNigger")
oc19 = readtext("GoodCountryPeople")
oc20 = readtext("YouCantBeAnyPoorerThanDeath")
oc21 = readtext("GreenLeaf")
oc22 = readtext("AViewOfTheWoods")
oc23 = readtext("TheEnduringChill")
oc24 = readtext("TheComfortsOfHome")
oc25 = readtext("EverythingThatRisesMustConverge")
oc26 = readtext("ThePartridgeFestival")
oc27 = readtext("TheLameShallEnterFirst")
oc28 = readtext("WhyDoTheHeathenRage")
oc29 = readtext("Revelation")
oc30 = readtext("ParkersBack")
oc31 = readtext("JudgementDay")
setwd("C:/Users/Justin/Desktop/TextData")
wordFrequenciesDataframe = f1
for(i in 2:20){
wordFrequenciesDataframe = merge(wordFrequenciesDataframe,
eval(parse(text=(paste("f", i, sep="")))),
by = "word",
suffixes = c(paste("f", 1:i, sep="")),
all = TRUE)
}
for(i in 1:31){
wordFrequenciesDataframe = merge(wordFrequenciesDataframe,
eval(parse(text=(paste("c", i, sep="")))),
by = "word",
suffixes = c(paste("c", 1:i, sep="")),
all = TRUE)
}
for(i in 1:32){
wordFrequenciesDataframe = merge(wordFrequenciesDataframe,
eval(parse(text=(paste("p", i, sep="")))),
by = "word",
suffixes = c(paste("p", 1:i, sep="")),
all = TRUE)
}
for(i in 1:20){
wordFrequenciesDataframe = merge(wordFrequenciesDataframe,
eval(parse(text=(paste("sp", i, sep="")))),
by = "word",
suffixes = c(paste("sp", 1:i, sep="")),
all = TRUE)
}
for(i in 1:35){
wordFrequenciesDataframe = merge(wordFrequenciesDataframe,
eval(parse(text=(paste("h", i, sep="")))),
by = "word",
suffixes = c(paste("h", 1:i, sep="")),
all = TRUE)
}
for(i in 1:31){
wordFrequenciesDataframe = merge(wordFrequenciesDataframe,
eval(parse(text=(paste("oc", i, sep="")))),
by = "word",
suffixes = c(paste("oc", 1:i, sep="")),
all = TRUE)
}
wordFrequenciesDataframe[is.na(wordFrequenciesDataframe)] = 0
colnames(wordFrequenciesDataframe) = c("word", paste("freq.f", 1:20, sep=""),
paste("freq.c", 1:31, sep=""),
paste("freq.p", 1:32, sep=""),
paste("freq.sp", 1:20, sep=""),
paste("freq.h", 1:35, sep=""),
paste("freq.oc", 1:31, sep=""))
saveRDS(wordFrequenciesDataframe, file = "wordFreqDF.RDS")
library(e1071)
library(DESeq2)
n = wordFrequenciesDataframe$word
wf.df = as.data.frame(t(wordFrequenciesDataframe[,-1]))
colnames(wf.df) = n
#wf.df$myfactor <- factor(row.names(wf.df))
#as.data.frame(colnames(wordFrequenciesDataframe))
#any(wf.df < 0)
columnDataUsed = as.data.frame(cbind(
colnames(wordFrequenciesDataframe)[-1],
c(rep("Fitzgerald", 20),
rep("Chekhov", 31),
rep("Pop Music", 32),
rep("Science Paper", 20),
rep("Hemingway", 35),
rep("OConnor", 31))))
colnames(columnDataUsed) = c("Frequency", "Author")
dds = DESeqDataSetFromMatrix(countData = t(wf.df),
colData = columnDataUsed,
design = ~1)
diagdds = dds
diagdds = estimateSizeFactors(diagdds)
diagdds = estimateDispersions(diagdds)
diagvst = getVarianceStabilizedData(diagdds)
numberOfSamples = ncol(wordFrequenciesDataframe)
transposedTermFreqMatrix = t(diagvst)
CV2 = matrix(rep(0,36),nrow = 6, ncol = 6)
rownames(CV2)=c("f","c","p","sp","h","oc")
colnames(CV2)=c("f","c","p","sp","h","oc")
trainingFlag = c(sample(1:20,15,replace=FALSE),
sample(21:51,15,replace=FALSE),
sample(52:83,15,replace=FALSE),
sample(84:103,15,replace=FALSE),
sample(104:138,15,replace=FALSE),
sample(139:169,15,replace=FALSE)
)
trainingSet = transposedTermFreqMatrix[trainingFlag,]
testingSet = transposedTermFreqMatrix[-trainingFlag,]
textDataClasses = c(rep("1", 20),
rep("2", 31),
rep("3", 32),
rep("4", 20),
rep("5", 35),
rep("6", 31))
y = textDataClasses[trainingFlag]
svmSolution = svm(trainingSet,y)
head(y)
head(trainingSet)
transposedTermFreqMatrix
dim(transposedTermFreqMatrix)
svmSolution = svm(trainingSet,y)
y = factor(textDataClasses[trainingFlag])
svmSolution = svm(trainingSet,y)
knnSolution3 = c(svmSolution, 1,2,3,4,5,6)
test = c(textDataClasses[-trainingFlag] , 1,2,3,4,5,6)
CV = table(knnSolution3, test)
CV[1,1] = CV[1,1]-1
CV[2,2] = CV[2,2]-1
CV[3,3] = CV[3,3]-1
svmSolution3 = c(svmSolution, 1,2,3,4,5,6)
test = c(textDataClasses[-trainingFlag] , 1,2,3,4,5,6)
CV = table(svmSolution3, test)
CV[1,1] = CV[1,1]-1
CV[2,2] = CV[2,2]-1
CV[3,3] = CV[3,3]-1
svmSolution3
str(svmSolution3)
pred <- predict(svmSolution, testingSet)
svmSolution3 = c(pred, 1,2,3,4,5,6)
test = c(textDataClasses[-trainingFlag] , 1,2,3,4,5,6)
CV = table(svmSolution3, test)
CV[1,1] = CV[1,1]-1
CV[2,2] = CV[2,2]-1
CV[3,3] = CV[3,3]-1
CV[4,4] = CV[4,4]-1
CV[5,5] = CV[5,5]-1
CV[6,6] = CV[6,6]-1
rownames(CV)=c("f","c","p","sp","h","oc")
colnames(CV)=c("f","c","p","sp","h","oc")
#CV2 = CV
CV2 = CV2 + CV
}
CV2
t(CV2)#transpose is what we want here
a = sum(diag(CV2))
b = sum(CV2)
a/b
plot(svmSolution, testingSet)
plot(svmSolution, testingSet, y~)
plot(svmSolution, testingSet, y~.)
plot(svmSolution, testingSet, y~1)
plot(svmSolution, testingSet, y~0)
plot(svmSolution, as.dataframe(testingSet), y~0)
plot(svmSolution, as.df(testingSet), y~0)
plot(svmSolution, as.data.frame(testingSet), y~0)
CV2 = matrix(rep(0,36),nrow = 6, ncol = 6)
rownames(CV2)=c("f","c","p","sp","h","oc")
colnames(CV2)=c("f","c","p","sp","h","oc")
for(i in 1:100){
trainingFlag = c(sample(1:20,15,replace=FALSE),
sample(21:51,15,replace=FALSE),
sample(52:83,15,replace=FALSE),
sample(84:103,15,replace=FALSE),
sample(104:138,15,replace=FALSE),
sample(139:169,15,replace=FALSE)
)
trainingSet = transposedTermFreqMatrix[trainingFlag,]
testingSet = transposedTermFreqMatrix[-trainingFlag,]
textDataClasses = c(rep("1", 20),
rep("2", 31),
rep("3", 32),
rep("4", 20),
rep("5", 35),
rep("6", 31))
y = factor(textDataClasses[trainingFlag])
svmSolution = svm(trainingSet,y)
#head(knnSolution)
#cbind(textDataClasses[-trainingFlag],knnSolution)
pred <- predict(svmSolution, testingSet)
svmSolution3 = c(pred, 1,2,3,4,5,6)
test = c(textDataClasses[-trainingFlag] , 1,2,3,4,5,6)
CV = table(svmSolution3, test)
CV[1,1] = CV[1,1]-1
CV[2,2] = CV[2,2]-1
CV[3,3] = CV[3,3]-1
CV[4,4] = CV[4,4]-1
CV[5,5] = CV[5,5]-1
CV[6,6] = CV[6,6]-1
rownames(CV)=c("f","c","p","sp","h","oc")
colnames(CV)=c("f","c","p","sp","h","oc")
#CV2 = CV
CV2 = CV2 + CV
}
CV2
t(CV2)#transpose is what we want here
a = sum(diag(CV2))
b = sum(CV2)
a/b
unnormalizedTransposedTermFreqMatrix = as.matrix(wf.df)
unnormalizedTransposedTermFreqMatrix = unnormalizedTransposedTermFreqMatrix/colSums(unnormalizedTransposedTermFreqMatrix)
CV2 = matrix(rep(0,36),nrow = 6, ncol = 6)
rownames(CV2)=c("f","c","p","sp","h","oc")
colnames(CV2)=c("f","c","p","sp","h","oc")
for(i in 1:100){
trainingFlag = c(sample(1:20,15,replace=FALSE),
sample(21:51,15,replace=FALSE),
sample(52:83,15,replace=FALSE),
sample(84:103,15,replace=FALSE),
sample(104:138,15,replace=FALSE),
sample(139:169,15,replace=FALSE)
)
#trainingSet = transposedTermFreqMatrix[trainingFlag,]
#testingSet = transposedTermFreqMatrix[-trainingFlag,]
trainingSet = unnormalizedTransposedTermFreqMatrix[trainingFlag,]
testingSet = unnormalizedTransposedTermFreqMatrix[-trainingFlag,]
textDataClasses = c(rep("1", 20),
rep("2", 31),
rep("3", 32),
rep("4", 20),
rep("5", 35),
rep("6", 31))
y = factor(textDataClasses[trainingFlag])
svmSolution = svm(trainingSet,y)
#head(knnSolution)
#cbind(textDataClasses[-trainingFlag],knnSolution)
pred <- predict(svmSolution, testingSet)
svmSolution3 = c(pred, 1,2,3,4,5,6)
test = c(textDataClasses[-trainingFlag] , 1,2,3,4,5,6)
CV = table(svmSolution3, test)
CV[1,1] = CV[1,1]-1
CV[2,2] = CV[2,2]-1
CV[3,3] = CV[3,3]-1
CV[4,4] = CV[4,4]-1
CV[5,5] = CV[5,5]-1
CV[6,6] = CV[6,6]-1
rownames(CV)=c("f","c","p","sp","h","oc")
colnames(CV)=c("f","c","p","sp","h","oc")
#CV2 = CV
CV2 = CV2 + CV
}
CV2
t(CV2)#transpose is what we want here
a = sum(diag(CV2))
b = sum(CV2)
a/b
398+71+1+5+25
1411+141+3+45
1+10+1637+11+41
32+51+417+
0
1+258+235+246+1277+3
2+1+37+422+1138+
0
1+238+235+246+1277+3
